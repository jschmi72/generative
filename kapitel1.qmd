---
title: "Kapitel 1 – KI als Hilfe zum Lehren und Lernen"
---

**Wie kann uns generative künstliche Intelligenz (KI)** in der Lehre helfen? Hoffnung besteht hier für zwei typische Probleme: Erstens haben Studierende **individuelle Bedürfnisse**, aber wir haben nur **begrenzte Zeit**, auf diese einzugehen. Wie können wir Einzelne möglichst intensiv fördern, ohne vor Arbeit unterzugehen? Zweitens ist der **Aufwand gerade für effektive Lehrmethoden** oft sehr hoch – so etwa für häufige niedrigschwellige Tests oder **individuelles Feedback zu Studienarbeiten** (s. etwa @Hattie2023Visible, Kap. 13; @Brown2014MakeItStick). Wer lehrt, fühlt sich aus Zeit- und Stoffdruck oft gezwungen, Abstriche von idealen Lehr-Setups zu machen (@Henderson2007Barriers; @Schmidt2005Besser, S. 104–105). Gerade Lehrmethoden, die didaktisch sinnvoll, aber mit hohem Aufwand verbunden sind, drohen dabei auf der Strecke zu bleiben (@Brown2014MakeItStick).

Für die Lehre erschließen sich durch die großen KI-Sprachmodelle (LLM = Large Language Models) neue Möglichkeiten. Sie sind – wie es eine Analyse des MIT-Professors Andrew McAfee auf den Punkt bringt – „**generally faster**“ (@McAfee2024Generally). Lehrende können mit KI-Unterstützung etwa deutlich schneller ein Set von Übungsaufgaben erstellen, mehrere Anwendungsbeispiele pro Konzept hinzufügen, Quizfragen zur schnellen Lernüberprüfung generieren oder mit den Studierenden Rollenspiele durchführen (@Meincke2024Prompting; @Mollick2023Assigning).

> Der Berg ist noch da, aber mit dem E-Bike kommt man weiter.

**Immer mehr Aspekte typischer Forschungstätigkeiten** – ein zentraler Ausbildungsinhalt der Hochschulen – können **zunehmend von der KI übernommen** werden, und zwar auf hohem Niveau. Vorbei sind die Zeiten, in denen wir die banalen Schreibprodukte der KI nur belächeln konnten. Ein Überblicksartikel des Forschers Anton Korinek im renommierten *Journal of Economic Literature* vom Dezember 2024 fasst das deutlich höhere Niveau zusammen:

> „Die derzeitige Generation von LLMs ist in hohem Maße in der Lage, die wichtigsten Erkenntnisse von Forschungsarbeiten zu verarbeiten.“\
> (@Korinek2024LLMs, S. 3; Übersetzung RB mit DeepL)

Die professionelle Nutzung ist hier noch weiter: So demonstrierte etwa Google (2025) ein mehrstufiges Modell für die Pharma-Forschung („**AI co-scientist**") , das den Forschenden zeitintensive Zwischenschritte abnimmt (@Gottweis2025Towards). Auch im Peer-Review werden zunehmend Sprachmodelle eingesetzt – mit allen Vor- und Nachteilen, die das mit sich bringt (@Naddaf2025AI). Wie wir in den späteren Kapiteln sehen, experimentieren Hochschulen weltweit intensiv mit den neuen Möglichkeiten für Lehre und Forschung.

**Drei zentrale Weiterentwicklungen** zwischen 2024 und 2025 sind laut @Korinek2024LLMs (S. 2–3) für den deutlichen Sprung in forschungsrelevanten Fähigkeiten der Sprachmodelle verantwortlich:

Erstens **neue Interaktionsmöglichkeiten** - Während die typische Nutzung früher auf Texteingabe im Eingabefenster beschränkt war, bieten die großen Sprachmodelle mittlerweile die Möglichkeit, in einem Workspace gemeinsam an Text oder Code zu arbeiten (z. B. ChatGPT Canvas, Claude Artifacts).

Zweitens eine deutliche Verbesserung der **Problemlösefähigkeit (Reasoning)** der Modelle. Den stärksten Modellen (GPT-5, Gemini 2.5, Claude Opus 4.1) kann man mittlerweile dabei zusehen, wie sie mehrstufiges Problemlösen und logisches Schlussfolgern etwa bei Rechercheaufgaben durchführen. Die Bedeutung präziser Prompt-„Zaubersprüche“ nimmt ab, da die neueren Reasoning-Modelle ohnehin selbst Schritt für Schritt vorgehen und nachfragen (@Meincke2025Prompting2). Insgesamt steigt seit 2023 die Qualität der Aufgaben, die Sprachmodelle erledigen können, stark an. Empirische Untersuchungen zeigen, dass die Modelle immer längere Aufgaben auf hohem Niveau bearbeiten können (@Kwa2025Measuring).

**Was ändert sich durch GPT-5?** Aus User-Sicht ist GPT-5 im Vergleich zu Vormodellen selbstständiger geworden – User müssen nicht mehr selbst zwischen vielen unterschiedlichen Modellen auswählen. Je nachdem, wie einfach die Frage ist, wird Schnelligkeit bevorzugt (durch Nutzung eines kleineren Modells wie GPT-5 nano) oder es wird ein schwereres Werkzeug angelegt (mehrstufiges Suchen und Reflektieren mit einem größeren Modell). Diese „schlaueren“ Reasoning-Modelle werden somit jetzt gerade für komplexere Fragen häufiger zur Anwendung kommen – nach Herstellerangaben stieg die Nutzung dieser stärkeren Modelle unter den zahlenden Usern von 7 % auf 24 %, was insgesamt die Qualität der Ergebnisse steigern sollte.Die neuen Modelle sind wiederum deutlich effizienter geworden, mit stark sinkenden Kosten pro Prompt. Eine Million Token kosteten mit GPT-4 noch 50 Dollar, jetzt nur noch 14 Cent [@InvertedStoneND; @Mollick2025GPT5; @Mollick2025Mass]. Das Modell halluziniert (weiterhin – also Vorsicht! – aber) deutlich seltener als seine Vorgänger: OpenAI gibt hier ca. 1 % Halluzinationen der Antworten statt ca. 5 % bei Vorgängermodellen (o3, 4o) an, je nach Komplexität der Frage und erlaubter „Bedenkzeit“ [@OpenAI2025GPT5Card; @OpenAI2025Introducing].

Drittens hat sich die **Internetsuche mit LLMs** deutlich verbessert. Während man früher noch oft über sinnlose oder erfundene Ergebnisse lachte, stellt die Suche von ChatGPT, Google / Gemini oder speziellen Suchanbietern wie Perplexity mittlerweile eine große Zeitersparnis dar: „a useful tool to provide up-to-date answers to questions that are grounded in facts found on the internet, together with the requisite citations — a crucial capability for researchers“ [@Korinek2024LLMs, S. 3]. Das gilt zunehmend für die stärksten allgemeinen Modelle und erst recht für Anbieter, die auf Forschungsrecherche (und Studierende) spezialisiert sind, wie Elicit oder Paperpal. Auch breite Internet-Recherchen und Textproduktionen sind zunehmend komplett delegierbar („deep research“), mit deutlichen Auswirkungen auf den Arbeitsprozess in der Wissensarbeit (s. etwa [@Schwarcz2025AI] für juristische Recherchen, [@Korinek2024LLMs] für Ökonomie und [@Liang2025Widespread] für PR-Tätigkeiten).

Auch **Studierende nutzen bereits umfangreich Sprachmodelle** für einen breiten Strauß an Zielen (s. *Abbildung 1*). Eine Auswertung der KI-Forscher:innen des Unternehmens Anthropic von einer Million anonymisierter Chats zwischen Usern mit Universitätskonto und dem KI-Bot zeigt typische Nutzungsmuster [@Handa2025Anthropic]: Studierende setzen das Sprachmodell **vor allem für anspruchsvolle Tätigkeiten** ein, wie das **Erstellen neuer Inhalte oder das Analysieren komplexer Themen**, was höheren Ebenen der Bloomschen Taxonomie entspricht. Daraus ergibt sich die Herausforderung, sicherzustellen, dass Studierende wesentliche kognitive Aufgaben nicht vollständig an KI delegieren: Aufgaben müssen angepasst und der verantwortungsvolle Umgang mit der Technik eingeübt werden.

![Abbildung 1: Wofür Studierende in unterschiedlichen Fachrichtungen LLMs nutzen](images/abbildung1.png) *Quelle:* @Handa2025Anthropic\]

**Auch außerhalb der Hochschule steigt die Nutzung.** Eine Reihe von Studien zeigen **erhöhte Produktivität von Büroarbeitenden mit LLM-Unterstützung:** der Kundensupport arbeitet 15% schneller, wenn das Sprachmodell Antwortoptionen vorschlägt und Verweise auf interne technische Dokumentation anbietet [@Brynjolfsson2025Generative], Programmierer programmieren schneller [@Peng2023Impact], Consultants sind produktiver bei komplexen Beratungsprojekten [@DellAcqua2023Navigating] und Sprachmodelle wie ChatGPT können eine Vielzahl kleiner Aufgaben beschleunigen [@Handa2025Which] und werden insofern gerade zur Texterstellung schon millionenfach als Hilfsmittel im Beruf genutzt: Von Kundenbewertungen über Pressemitteilungen und Stellenanzeigen [@Liang2025Widespread].

Die zunehmende Verwendung von KI in der Lehre hat gute Gründe. Wie oft eine neue Technologie genutzt wird, hängt nach dem **Technology Acceptance Model** (TAM) von der **wahrgenommenen Benutzerfreundlichkeit** (perceived ease of use) und der **wahrgenommenen Nützlichkeit** (perceived usefulness) ab [@Marangunic2015Technology]. Generative KI wie ChatGPT decken sichtlich beide Aspekte ab: Sie sind einfach zu nutzen [@Kestin2024AI; @Lee2025Impact; @Monib2025Exploring; @Naddaf2025How] und erzeugen einen deutlichen Mehrwert, wie Studierende und Lehrende in einer Vielzahl von Umfragen der letzten zwei Jahren berichten [@Heidt2025ChatGPT; @Morgan2024What; @Ou2024Academic]. Lehrende ziehen nach: Meta-Untersuchungen zeigen ein extremes Wachstum an Publikationen zur Nutzung von LLM im Hochschulalltag [@Ma2025Systematically; @Ogunleye2024Systematic].

Der Metapher mit dem E-Bike trägt allerdings auch, was die **Risiken und Nebenwirkungen** angeht: Ab wann lässt die maschinelle Unterstützung wichtige Muskeln verkümmern? Solche Gefahren bestehen – wie empirische Studien zeigen, erfordern die neuen Workflows der Wissensarbeit durch KI-Unterstützung auch neue Formen der kritischen Auseinandersetzung mit den Inhalten. Die Analyse von 1 Millionen anonymisierten Studierenden-Chats durch Anthropic [@Handa2025Anthropic] zeigt einerseits, dass **Studierende das LLM vor allem für kognitiv anspruchsvollere Aufgaben einsetzen,** vor allem in den Kategorien „Creating“ und „Analyzing“ (s. *Abbildung 2*). Dies steht im deutlichen Gegensatz zur Nutzung von einfachen Internetsuchen, die einen Schwerpunkt auf dem Finden einzelner Fakten haben.

![Abbildung 2: Schwerpunkte der Nutzung von LLMs (Claude) durch Studierende nach der Bloom’schen Taxonomie](images/abbildung2.png)\
*Quelle:* @Handa2025Anthropic\]

Wie kann man verhindern, dass die Studierenden kritische kognitive Aufgaben allein den KI-Systemen übergeben? Eine Studie von 319 Wissensarbeitern zeigt, dass sich das Gewicht zwischen den **Einzelaufgaben der Wissensarbeit mit LLMsm verschiebt:** Der Aufwand für die Recherchen selbst sinkt, es steigt anderseits der Aufwand für Management-ähnliche Aufgaben: Koordination der Einzelaufgaben für Mensch und Maschine, kritische Prüfung der berichteten Ergebnisse und die Integration von Ergebnissen in den Gesamtprozess (etwa zur Erstellung eines Gesamtberichtes, einer Test-Spezifikation oder eines Protokolls) [@Lee2025Impact]. Werden solche neuen Vorgehensweisen nicht geübt, droht ein Rückgang des kritischen Denkens. Lehre heißt in diesem Kontext auch, empfohlene Arbeitsweisen mit der neuen Technik zu üben.

Im Folgenden werden wir zunächst einige **Grundbegriffe** klären: Was sind große Sprachmodelle und was ist mit Begriffen wie Token, Prompt und RAG gemeint? **Welche Modelle** können Lehrende aktuell nutzen und welche **Empfehlungen für Prompts** sind belastbar (Abschnitt 2.5)? Dann fragen wir nach **Zielen**: Welche Art von Wissen und Methoden unterscheidet und empfiehlt die Lernforschung? Welche **didaktischen Wirkmechanismen** können durch KI genutzt werden, um typische Probleme der Hochschullehre anzugehen (Abschnitt 3)? Im Abschnitt 4 schauen wir auf **Praxisbeispiele** für vier Anwendungsfelder von Sprachmodellen an Hochschulen: **KI als Hiwi** (direkte Arbeitserleichterung), **KI als Copilot** (Unterstützung beim Schreiben und Coden) und KI als Tutor (Feedback und Lernunterstützung) sowie **KI als Simulator** (Role Play und Goal Play). Abschließend zeigen wir verschiedene Anwendungen von KI in verschiedenen Kurstypen und gehen auf neue **Herausforderungen für Prüfungen** ein (Abschnitt 5). Im Appendix werden Risiken von KI, rechtliche Rahmenbedingungen und konkrete Prompts und Aufgabenbeispiele aufgeführt.

